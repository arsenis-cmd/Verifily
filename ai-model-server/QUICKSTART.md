# Quick Start - AI Model Server

## Test on Same Computer First

### Step 1: Install Dependencies

```bash
cd ai-model-server
pip3 install -r requirements.txt
```

**Wait ~2-5 minutes** - First time downloads the AI model (~500MB)

### Step 2: Start Model Server

```bash
python3 server.py
```

You should see:
```
üöÄ Starting AI Detection Model Server
üîÑ Loading AI detection model...
   Device: cpu
‚úÖ Model loaded: roberta-base-openai-detector
   Parameters: 124,697,433
   Ready to detect AI text!
INFO:     Uvicorn running on http://0.0.0.0:5000
```

### Step 3: Test the Model

Open a new terminal:

```bash
# Test with your AI text that failed before
curl -X POST http://localhost:5000/detect \
  -H "Content-Type: application/json" \
  -d '{"text": "I'\''m driven by the act of creating‚Äîturning ideas into systems that actually work. There'\''s a specific moment I chase: when code compiles, when logic clicks, when something that didn'\''t exist an hour ago suddenly does."}'
```

**Expected result:**
```json
{
  "ai_probability": 0.92,  ‚Üê High! (Was 0.16 before)
  "human_probability": 0.08,
  "confidence": 0.84,
  "model_name": "roberta-base-openai-detector"
}
```

### Step 4: Test Through Main Backend

Keep model server running, in another terminal test the main backend:

```bash
curl -X POST http://localhost:8000/api/v1/detect \
  -H "Content-Type: application/json" \
  -d '{"content": "I'\''m driven by the act of creating‚Äîturning ideas into systems that actually work.", "source_platform": "test"}'
```

Should now return **AI** classification with high probability!

---

## If You Want to Run on a Different Computer

### On Model Server Computer:

1. Copy the `/Users/arsenispapachristos/Desktop/SDK_PoC/poc-mvp/ai-model-server` folder to the other computer

2. Install dependencies:
```bash
cd ai-model-server
pip3 install -r requirements.txt
python3 server.py
```

3. Find the IP address:
```bash
ifconfig  # macOS/Linux
# Look for something like: inet 192.168.1.100
```

### On Your Main Computer:

Edit `backend/.env`:
```bash
AI_MODEL_SERVER_URL=http://192.168.1.100:5000
```

Restart backend:
```bash
cd backend
python3 -m uvicorn app.main:app --reload --port 8000
```

---

## Troubleshooting

### "Module not found: transformers"
```bash
pip3 install transformers torch
```

### "Connection refused"
- Make sure model server is running: `curl http://localhost:5000/health`
- Check firewall settings

### "Slow on CPU"
- Normal! CPU takes 200-500ms per detection
- Still faster than paid APIs
- For speed: use GPU or paid API

---

## Performance Comparison

| Method | Speed | Accuracy | Cost |
|--------|-------|----------|------|
| Pattern Matching (current) | 10ms | 60% | Free |
| **RoBERTa Model (new)** | **200ms (CPU)** | **88%** | **Free** |
| RoBERTa + GPU | 50ms | 88% | Free |
| GPTZero API | 500ms | 92% | $10/mo |

**Recommendation:** Start with RoBERTa on localhost, upgrade to separate computer with GPU later if needed.

---

Ready to test! üöÄ
